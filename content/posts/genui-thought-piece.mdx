---
title: "The Canvas, Not the Form: Rethinking AI Interfaces"
description: "Why AI should compose communications, not just answer questions"
publishedAt: "2026-01-15"
tags: ["AI", "GenUI", "Design"]
---

Templates decide what matters. Not the AI.

When I built an AI assistant for sales forecasting, I started with the obvious approach: structured outputs, fixed HTML templates, predefined sections. Executive Summary here. Risks there. Recommendations at the bottom.

It worked. It was also wrong.

Three deals representing 80% of quarterly risk appeared in the Risks section with the same visual weight as minor concerns. A dangerously thin forward-year pipeline sat in its designated accordion, unexpanded, waiting to be noticed. The AI saw the problem. The template wouldn't let it say so.

We've been asking AI to answer questions when we should be asking it to compose communications.

## The Template Trap

[Google's Generative UI research](https://research.google/blog/generative-ui-a-rich-custom-visual-interactive-user-experience-for-any-prompt/) articulated what we were missing: *"explaining the microbiome to a 5 year old requires different content and a different set of features than explaining it to an adult."*

The same applies to data. A healthy pipeline needs different presentation than a pipeline in crisis. The AI sees the data. The AI should decide the form.

## Vocabulary, Not Grammar

The solution isn't arbitrary interface generation. That way lies inconsistency and security nightmares. Instead: give the AI a vocabulary of components and let it compose.

Think of it as the difference between asking someone to write a sentence (grammar constrains but expression is free) versus asking them to fill a form (slots constrain and expression is limited).

Our vocabulary includes structural components, emphasis signals, and domain-specific elements. The AI composes these based on what the data demands. Three blocked deals? Lead with them, expanded, highlighted. Strong coverage? Summary with confident indicators. Mixed signals? Side-by-side comparison.

The styling is ours. The structure is ours. The composition is the AI's.

## What We Learned

Letting AI control form sounds simple. The implementation revealed complications.

**The AI invents things.** We documented data path syntax carefully. The AI still generated creative variations that broke the renderer. Explicit examples of wrong patterns helped more than documentation of right ones.

**Editorial choices can be wrong.** The AI occasionally buries important information. We haven't solved this; user override is on the roadmap.

**Debugging gets harder.** When every response has different structure, you can't diff against expected output. We store full prompts with responses. Investigating issues means understanding what the AI saw and why it chose what it chose.

**Vocabulary design is harder than template design.** Adding a new component means updating types, rendering logic, documentation, and prompts. The barrier to change is higher. This is probably good: it forces intentionality.

## The Trade We Made

Templates are predictable. You know exactly what you're getting. Testing is straightforward. Debugging is simple.

Component vocabulary is adaptive. The AI can emphasize what matters. But testing is harder, debugging requires more context, and prompt engineering becomes a critical skill.

We made the trade because predictability was costing us value. The AI had insights the template wouldn't let it express.

We don't have systematic data on whether managers prefer the adaptive layouts. That measurement should have been built in from day one. Early feedback has been positive, but we're operating on intuition more than evidence. If you build something similar, instrument it.

Not every domain needs this trade. Chat interfaces work fine as forms. Search results work fine as lists. But analysis (synthesis of complex data into actionable understanding) benefits from adaptive form.

## Beyond Fill-in-the-Blank

The shift from templates to component vocabulary reflects a broader principle: stop treating AI as a function that maps inputs to outputs and start treating it as a collaborator that can make judgment calls within constraints.

We define the vocabulary. We control the styling. We set the boundaries. Within those boundaries, the AI has agency to communicate effectively.

The AI provides guidance. The human makes the judgment call. The interface should serve both.

The best AI interface isn't a form with smart answers. It's a canvas with smart composition.

---

*For implementation details, failure modes, and code examples, see the companion piece: [From Templates to Component Vocabulary](/writing/genui-technical)*
